# Optimization-Based Control of Hybrid Systems

[toc]

# 1. Optimal Control of Hybrid Systems

## 1.1. Optimal Control for Hybrid Manufacturing Systems

### Introduction of Manufacturing Systems

* Jobs move through network of work centers.
* Jobs have two kinds of state:
  * **temporal state** (event-driven): waiting time, departure time, . . . 
  * **physical state** (time-driven): temperature, size, weight, chemical composition
* Always need make trade-off:
  * temporal requirements on job **completion times** 
  * physical requirements on **quality** of completed jobs

### Model of Manufacturing Systems

* Each job corresponds to mode

* As job $i$ is processed, physical state $z_i$ evolves according to

$$
\dot{z}_{i}=g_{i}\left(z_{i}, u_{i}, t\right) \quad \text { with } z_{i}\left(\tau_{i}\right)=\zeta_{i}
$$

​				with $τ_i$ time instant at which processing begins

* **Control variable** $u_{i}$ is used to attain final desired physical state:
  If $s_{i}\left(u_{i}\right)$ is service time and $\Gamma_{i}\left(u_{i}\right)$ is target quality set, then
  $$
  s_{i}\left(u_{i}\right)=\min \left\{t \geqslant 0 \mid z_{i}\left(\tau_{i}+t\right) \in \Gamma_{i}\left(u_{i}\right)\right\}
  $$

* Temporal state $x_{i}$ represents time when job is completed:
  If $a_{i}$ is arrival time of job $i$, then
  $$
  x_{i}=\max \left(x_{i-1}, a_{i}\right)+s_{i}\left(u_{i}\right) \quad \text { (Lindley equation) }
  $$

### Control Problem Model

Optimal control problem:
$$
\min _{u_{1}, \ldots, u_{N}} J=\sum_{i=1}^{N} L_{i}\left(x_{i}, u_{i}\right)\\
\text{subject to evolution equations for $z_{i}$ and $x_{i}$}
$$

where $L\left(x_{i}, u_{i}\right)$ is cost function associated with job $i$

* max is non-differentiable for $a_{i}=x_{i-1}$
  $\rightarrow$ prevents use of standard gradient-based techniques (classical discrete-time optimal control method cannot use)
  $\rightarrow$ use non-differentiable calculus, generalized gradient

## 1.2. An example





## 1.3. Optimality Conditions

### Generalized Gradient: Deal with non-differentiability

$\max$ is Lipschitz continuous + differentiable except for $x_{i}=a_{i+1}$ :
$$
\frac{d \max \left(x_{i}, a_{i+1}\right)}{d x_{i}}=\left\{\begin{array}{ll}
0 & \text { if } x_{i}<a_{i+1} \\
1 & \text { if } x_{i}>a_{i+1}
\end{array}\right.
$$
Let $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ be locally Lipschitz continuous, and let $S(u)$ denote set of all sequences $\left\{u_{m}\right\}_{m=1}^{\infty}$ that satisfy \bullet $u_{m} \rightarrow u$ as $m \rightarrow \infty$
- gradient $\nabla f\left(u_{m}\right)$ exists for all $m$ 
- $ \lim _{m \rightarrow \infty} \nabla f\left(u_{m}\right)=\phi$ exists

Then **<u>generalized gradient</u>** $\partial f(u)$ is defined as **convex hull** of all limits $\phi$ corresponding to some sequence $\left\{u_{m}\right\}_{m=1}^{\infty}$ in $S(u)$



### Properties of Generalized Gradient

Properties of generalized gradient:
- if $f$ is continuously differentiable in some open set containing $u$, then $\partial f(u)=\{\nabla f(u)\}$
- if $u$ is local minimum, then $0 \in \partial f(u)$ $\rightarrow$ this becomes first-order optimality condition in non-smooth optimization
- $\partial f(u)$ is a nonempty, compact and convex set in  $\mathbb{R}^{n}$



### Computation of Generalized Gradient

See Lecture Notes

# 2. MPC Method for Hybrid Systems

## 2.1. Introduction of MPC

![image-20210514200516905](assets/image-20210514200516905.png)

## 2.2. MPC for MLD systems

### System Model

$$
\begin{array}{r}
x(k+1)=A x(k)+B_{1} u(k)+B_{2} \delta(k)+B_{3} z(k) \\
y(k)=C x(k)+D_{1} u(k)+D_{2} \delta(k)+D_{3} z(k) \\
E_{1} x(k)+E_{2} u(k)+E_{3} \delta(k)+E_{4} z(k) \leqslant g_{5}
\end{array}
$$
* $x(k)=\left[x_{\mathrm{r}}^{\top}(k) x_{\mathrm{b}}^{\top}(k)\right]^{\top}$ with $x_{\mathrm{r}}(k)$ real-valued, $x_{\mathrm{b}}(k)$ boolean
* $z(k):$ real-valued auxiliary variables
* $\delta(k):$ boolean auxiliary variables
* Consider Well-Posed System, that means: $\left(x_{\mathrm{eq}}, u_{\mathrm{eq}}, y_{\mathrm{eq}}\right) \rightarrow\left(\delta_{\mathrm{eq}}, z_{\mathrm{eq}}\right)$
* $\hat{x}(k+j \mid k):$ estimate of $x$ at sample step $k+j$ based on information available at sample step $k$

### Control Problem

**Stabilize system to equilibrium state:**
$$
\begin{aligned}
J(k)=\sum_{j=1}^{N_{\mathrm{p}}} &\left\|\hat{x}(k+j \mid k)-x_{\mathrm{eq}}\right\|_{Q_{x}}^{2}+\left\|u(k+j-1)-u_{\mathrm{eq}}\right\|_{Q_{u}}^{2}+\\
&\left\|\hat{y}(k+j \mid k)-y_{\mathrm{eq}}\right\|_{Q_{y}}^{2}+\left\|\hat{\delta}(k+j-1 \mid k)-\delta_{\mathrm{eq}}\right\|_{Q_{\delta}}^{2}+\\
&\left\|\hat{z}(k+j-1 \mid k)-z_{\mathrm{eq}}\right\|_{Q_{2}}^{2}
\end{aligned}
$$
with $Q_{i} \geq 0$ : for $x$ and $u$, $Q>0$, 

* End-point condition: $\hat{x}\left(k+N_{\mathrm{p}} \mid k\right)=x_{\mathrm{eq}}$
* Control horizon constraint:
  $u(k+j)=u\left(k+N_{\mathrm{c}}-1\right)$ for $j=N_{\mathrm{c}}, \ldots, N_{\mathrm{p}}-1$

### Property

If feasible solution exists for $x(0)$, then MPC input stabilizes system, i.e.,
$$
\begin{array}{lll}
\lim _{k \rightarrow \infty} x(k) & =x_{\mathrm{eq}} & \lim _{k \rightarrow \infty}\left\|y(k)-y_{\mathrm{eq}}\right\|_{Q_{y}}=0 & \lim _{k \rightarrow \infty}\left\|z(k)-z_{\mathrm{eq}}\right\|_{Q_{z}}=0 \\
\lim _{k \rightarrow \infty} u(k) & =u_{\mathrm{eq}} & \lim _{k \rightarrow \infty}\left\|\delta(k)-\delta_{\mathrm{eq}}\right\|_{Q_{\delta}}=0 &
\end{array}
$$
Explanation:

$x$, $u$ with no norm because Q of them are positive. For others, we use norm because Q of them are semi-positive

### Mixed-integer Quadratic Programming (MIQP): Algorithms for MLD-MPC



## 2.3. MPC for continuous PWA systems and MMPS systems

### Equivalence of Continuous PWA and MMPS systems

**<u>Continous PWA</u>**: PWA with continuous over boarder of any two regions

* Any MMPS function is also continuous PWA

* A continuous PWA function $f$ can be rewritten as
  $$
  f=\max _{j} \min _{i}\left(\alpha_{i}^{T} x+\beta_{i}\right)
  $$
  $\rightarrow f$ is also MMPS function

* Continuous PWA systems and MMPS systems are equivalent:
  $\rightarrow$ for given continuous PWA model **there exists MMPS model** (and vice versa) such that input-output behaviors coincide
  $\Rightarrow$ **use properties \& techniques** from continuous PWA systems for MMPS systems and vice versa

### Canonical forms of MMPS functions

Any MMPS function $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ can be rewritten into **<u>min-max canonical form</u>**
$$
f=\min _{i} \max _{j}\left(\alpha_{(i, j)}^{T} x+\beta_{(i, j)}\right)
$$
or into **<u>max-min canonical form</u>**
$$
f=\max _{i} \min _{j}\left(\gamma_{(i, j)}^{T} x+\delta_{(i, j)}\right)
$$

### MPC for MMPS Systems

* Estimate $\hat{y}(k+j \mid k)$ of output at sample step $k+j$ :

$$
\hat{y}(k+j \mid k)=F_{j}(x(k-1), u(k), \ldots, u(k+j))
$$
​					$\rightarrow F_{j}$ is MMPS function!

* Cost criterion $J$ : reference tracking $\left(J_{\text {out }}\right)$ vs control effort $\left(J_{\text {in }}\right)$ :
  $$
  J(k)=J_{\text {out }}(k)+\lambda J_{\text {in }}(k) \quad \text { with } \lambda>0
  $$
  Some possible cost functions:
  $$
  \begin{aligned}
  J_{\text {out }, 1}(k) &=\|\tilde{y}(k)-\tilde{r}(k)\|_{1} & J_{\text {out }, \infty}(k) &=\|\tilde{y}(k)-\tilde{r}(k)\|_{\infty} \\
  J_{\text {in }, 1}(k) &=\|\tilde{u}(k)\|_{1} & J_{\text {in }, \infty}(k) &=\|\tilde{u}(k)\|_{\infty}
  \end{aligned}
  $$
  with
  $$
  \begin{array}{l}
  \tilde{u}(k)=\left[u^{T}(k) \ldots u^{T}\left(k+N_{\mathrm{p}}-1\right)\right]^{T} \\
  \tilde{y}(k)=\left[\hat{y}^{\top}(k \mid k) \ldots \hat{y}^{\top}\left(k+N_{\mathrm{p}}-1 \mid k\right)\right]^{T} \\
  \tilde{r}(k)=\left[r^{T}(k) \ldots r^{T}\left(k+N_{\mathrm{p}}-1\right)\right]^{T}
  \end{array}
  $$
  Note: $|x|=\max (x,-x) \rightarrow$ cost functions are MMPS functions

* Constraints: Constraints on input and output signals:
  $$
  C_{\mathrm{c}}(k, x(k-1), \tilde{u}(k), \tilde{y}(k)) \geqslant 0
  $$

### Algorithms for MMPS-MPC: Approach based on canonical forms

Collection of linear programming problems

Assume: linear (or convex) constraint in $\tilde{u}(k)$
$$
P(k) \tilde{u}(k)+q(k) \geqslant 0
$$
Recall: $J(k)$ is MMPS function
$$
\begin{aligned} \Rightarrow J(k)=& \max _{i}\left(\min _{j}\left(\gamma_{(i, j)}^{T} \tilde{u}+\delta_{(i, j)}\right)\right) \\=& \min _{i}\left(\max _{j}\left(\alpha_{(i, j)}^{T} \tilde{u}+\beta_{(i, j)}\right)\right) \\ \Rightarrow \min _{\tilde{u}} J(k)=& \min _{\tilde{u}} \min _{i}\left(\max _{j}\left(\alpha_{(i, j)}^{T} \tilde{u}+\beta_{(i, j)}\right)\right) \\=& \min _{i} \underbrace{\min _{\tilde{u}}\left(\max _{j}\left(\alpha_{(i, j)}^{T} \tilde{u}+\beta_{(i, j)}\right)\right)}_{\rightarrow \mathrm{LP!}} \end{aligned}
$$
So the problem is transformed to:

LP $i$: set of linear programming problems
$$
\begin{array}{l}
\min _{\tilde{i}} t\\
\text { s.t. }\left\{\begin{array}{l}
t \geqslant \alpha_{(i, j)}^{T} \tilde{u}+\beta_{(i, j)} \text { for all } j \\
P \tilde{u}+q \geqslant 0
\end{array}\right.
\end{array}
$$


# 4. Game-Theoretic Approaches

 ## 4.1. Background

Safety-critical applications such as collision avoidance in free flight or automated highways:

* guarantee safety even in case intentions of other aircraft/vehicle are not known **(non-cooperative game)** 
* if (partial) communication possible → **cooperative game**



## 4.2. Model

Consider **continuous-time system**
$$
\dot{x}=f(x, u, d)
$$
with $u$ control inputs (corresponding to 1 st player), and $d$ disturbance inputs (corresponding to 2nd player/adversary)

* Assume safety constraints can be represented by set
  $$
  F=\{x \in X \mid S(x) \geqslant 0\}
  $$

## 4.3. Optimization Format

Let $t_{0} \leqslant t_{\text {end }}$ and consider cost function
$$
J: X \times \mathscr{U} \times \mathscr{D} \times\left[t_{0}, t_{\text {end }}\right] \rightarrow \mathbb{R}:(x, u(\cdot), d(\cdot), t) \mapsto S\left(x\left(t_{\text {end }}\right)\right)
$$
where $\mathscr{U}$ and $\mathscr{D}$ denote admissible control and disturbance functions

* Cost is function of final state $x(t_{end})$ only

Value Function: 
$$
J^{\star}(x, t)=\max _{u \in \mathscr{U}} \min _{d \in \mathscr{D}} J(x, u, d, t)
$$

$$
\left\{x \in X \mid \min _{\tau \in\left[t, t_{\text {end }}\right]} J^{\star}(x, \tau) \geqslant 0\right\}
$$
contains all states for which system **can be forced by control** $u$ to **remain in safe set** $F$ for at least $\left|t_{\text {end }}-t\right|$ time units, irrespective of disturbance function $d$

> For all trajectory in the given time interval, although other parts gives worst condition, we can always find a way to maximize our beneficiency

Value function $J^⋆$ can be computed using **Hamilton-Jacobi equations**

